# Модули обработки данных

Данный каталог содержит модули для извлечения и векторизации текстовых данных из PDF-файлов.

---

## `extract_pdf.py`

Модуль для асинхронного извлечения текста из PDF-файлов с использованием библиотеки `pdfplumber` и пулов потоков.

### Основные функции:

### `extract_text_from_pdf(pdf_path, queue, loop)`

- **Назначение**: Синхронная функция, извлекающая текст постранично из PDF и передающая его в асинхронную очередь.
- **Выполняется в отдельном потоке**, чтобы не блокировать основной event loop.
- **Параметры**:
  - `pdf_path`: путь к PDF-файлу.
  - `queue`: асинхронная очередь (`asyncio.Queue`) для передачи текста.
  - `loop`: цикл событий для вызова `queue.put()` из потока.
- **Поведение**:
  - Извлекает текст каждой страницы.
  - Отправляет текст в очередь с добавлением `\n`.
  - В конце посылает `None` для обозначения завершения.
  - В случае ошибки помещает исключение в очередь.

### `async_extract_text_from_pdf(pdf_path, queue_size=10)`

- **Назначение**: Асинхронный генератор, запускающий `extract_text_from_pdf` в пуле потоков и возвращающий текст постранично.
- **Параметры**:
  - `pdf_path`: путь к PDF-файлу.
  - `queue_size`: максимальный размер очереди (буферизация).
- **Возвращает**: `AsyncGenerator[str, None]` — строки текста по мере извлечения.
- **Обработка ошибок**: Исключения из потока пробрасываются в асинхронный контекст.

### `save_text_from_pdf(from_pdf_path, save_text_path)`

- **Назначение**: Асинхронно извлекает текст из PDF и сохраняет его в текстовый файл.
- **Потокобезопасна**, использует `aiofiles` для асинхронной записи.
- **Поведение**:
  - Читает текст по частям.
  - Записывает в файл по мере поступления.
  - Логирует успех или ошибку.
- **Исключения**: Пробрасываются после логирования.

---

## `vectorize.py`

Модуль для асинхронной векторизации текста с использованием `SentenceTransformer`.

### Основные функции:

### `get_text(file_path, max_text_length)`

- **Назначение**: Асинхронно читает текст из файла порциями заданной длины.
- **Поведение**:
  - Считывает файл построчно.
  - Накапливает строки до достижения `max_text_length`.
  - Возвращает порции текста через `yield`, избегая разрыва на середине строки.
  - Очень длинные строки режутся принудительно.
- **Использует** `aiofiles` для асинхронного чтения.
- **Исключения**: `FileNotFoundError`, `PermissionError`, `UnicodeDecodeError`.

### `vectorize_text(model, splitter, text_func, file_path, sample_text_size=2621440, vector_batch_size=32)`

- **Назначение**: Преобраз��ет текст из файла в эмбеддинги.
- **Параметры**:
  - `model`: модель `SentenceTransformer`.
  - `splitter`: `RecursiveCharacterTextSplitter` для разбиения на чанки.
  - `text_func`: асинхронная функция для чтения текста (например, `get_text`).
  - `file_path`: путь к файлу.
  - `sample_text_size`: размер порции текста (по умолчанию ~2.5 МБ).
  - `vector_batch_size`: размер пакета при векторизации.
- **Возвращает**: `AsyncGenerator[torch.Tensor, None]` — тензоры с эмбеддингами.
- **Особенности**:
  - Поддерживает большие файлы.
  - Использует пакетную векторизацию для эффективности.
  - Требует `sentence-transformers`, `langchain`, `torch`.
