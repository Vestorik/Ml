import torch.nn as nn


class CNN(nn.Module):
    """
    Свёротчная нейронная сеть,
    использует последовательно связаные слои Sequential
    """

    def __init__(self, num_classes: int, input_size: int):
        """
        num_classes - количество классов для класификации
        input_size - Размерность входных данных прим.: 32*32  
        
        ! для нахождения ошибки использовать 
        self.loss = nn.CrossEntropyLoss()
        
        Основные слои:
            self.fetaures - это основная последовательность из 5 слоёв, ожидается 3 канала
            
                1 lAYER:
                Свёртка извлекает 16 признаков с помощью фильтров 3×3.
                BatchNorm нормализует активации по батчу.
                ReLU добавляет нелинейность и обнуляет отрицательные значения.
                MaxPool уменьшает размер в 2 раза по высоте и ширине (сжимает пространственное разрешение).

                Размерность меняется так (для входа 3×32×32):
                После conv1: 16×32×32 (из‑за padding=1).
                После bn1: та же размерность 16×32×32.
                После relu1: та же 16×32×32.
                После pool1: 16×16×16 (размер уменьшился в 2 раза).
            
            
            self.classifier -  полносвязную часть сети, 
            которая преобразует признаки из свёрточных слоёв в финальные предсказания классов.
        """
        super(CNN, self).__init__()  # Инициализируем экземпляр модели

        # MaxPool2d уменьшает размер в два раза по высоте и ширине, 
        # поэтому размерность уменьшается в 4 раза для одного слоя MaxPool2d
        # всего слоёв 2  
        input_size = input_size // (2*2)**2
       
        # Опеределяем слои
        self.features = nn.Sequential(
            nn.Conv2d(  # Это свёрточный слой  2D convolution
                in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1
            ),
            # in_channels=3 Количество входных каналов. Для RGB‑изображений — 3 (красный, зелёный, синий
            
            # out_channels=16 Сколько фильтров (ядер свёртки) применяется. Каждый фильтр «ищет» свой признак
                # Глубокие слои комбинируют сложные признаки (формы, объекты) → нужно больше фильтров. 16–32, conv2: 32–64, conv3: 64–128.
                # для подбора out_channels используется нейронный архитектурный поиск (NAS) или гиперпараметрический оптимизатор (Optuna, Hyperopt)
            
            # kernel_size=3 Размер фильтра (ядра свёртки) — матрица 3×3. Чем больше ядро, тем шире область восприятия, но больше параметров.
            # stride=1 Шаг сдвига фильтра по изображению. stride=1 — фильтр двигается на 1 пиксель за шаг.
            # padding=1 Дополнение нулями по краям изображения.
            
            nn.BatchNorm2d(16),  # Это слой пакетной нормализации
            # 16 — количество каналов на входе (совпадает с out_channels предыдущего свёрточного слоя).
            #  Для каждого канала (из 16) нормализует активации по батчу:
            
            nn.ReLU(inplace=False),  # Это функция активации ReLU
            # ReLU(x) = max(0, x)
            
            nn.MaxPool2d(kernel_size=2, stride=2),  # Это слой максимального пулинга
            # kernel_size=2  размер окна пулинга: 2×2 пикселя.
            # stride=2 шаг сдвига окна: 2 пикселя (по горизонтали и вертикали)
            #  Для каждого канала независимо:
                # Разбивает вход на непересекающиеся окна 2×2.
                # В каждом окне выбирает максимальное значение.
                # Формирует выход, где каждый элемент — максимум своего окна.
              
            #  Ввод 16*16*16 
            nn.Conv2d(16, 32, 3, 1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            
            #  Ввод 32*16*16
            nn.Conv2d(32, 32, 3, 1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),

            #  Ввод 32*8*8
            nn.Conv2d(32, 32, 3, 1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            
            #   Ввод 32*8*8
            nn.Conv2d(32, 32, 3, 1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            
                        #   Ввод 32*8*8
            nn.Conv2d(32, 32, 3, 1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU()
        )

        
        self.classifier = nn.Sequential(
            nn.Dropout(0.5), #  вероятность обнуления каждого элемента на этапе обучения
            nn.Linear(
                in_features=32 * input_size, out_features=128
            ),  # полносвязный (линейный) слой.   y=Wx+b, где W — матрица весов (10(32⋅16⋅16)), b — вектор смещений.
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(in_features=128, out_features=num_classes),
        
        )


    
    def forward(self, input_data):
        """
        Обучаем модель
        """
        x = self.features(input_data)
        x = x.flatten(start_dim=1)  
        y = self.classifier(x)
        return y